<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="styles.css" />
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  </head>
  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ["$", "$"],
          ["\\(", "\\)"],
        ],
      },
      svg: {
        fontCache: "global",
      },
    };
  </script>
  <script
    type="text/javascript"
    id="MathJax-script"
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
  ></script>
  <head>
    <title>Final Proj</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 20px;
      }
    </style>
  </head>
  <body>
    <h1>Final Project - Neural Radiance Field!</h1>

    <h2>Part 1 - The Power of Diffusion Models!</h2>

    <h3>By Ethan Chen</h3>

    <h2>Introduction</h2>

    <p>
      I chose to do the NeRF project for my final project, which aims to train neural networks to
      generate 3D objects from 2D images through an interpolation approach between the scenes.
    </p>

    <h2>Part 1: Fit a Neural Field to a 2D Image</h2>

    <p>
      We first start with a neural field that fits and represents a 2D image. The Multilayer
      Perception (MLP) network usese Sinusoidal Positional Encoding (PE) that maps the u, v
      coordinates of the image to rgb in 2D. The architecture is as follows:
    </p>

    <div class="image-container-1-wide">
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/mlp_img.jpg" alt="mlp_img.jpg" />
        </div>
      </div>
    </div>

    <p>
      Now, we do a hyperparameter sweep on the hyperparameters L, which is the highest frequency
      level in PE, and the learning rate of the MLP.
    </p>

    <div class="image-container-2-wide">
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/psnr_tune_hyperparam_L.png" alt="psnr_tune_hyperparam_L.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/psnr_tune_hyperparam_lr.png" alt="psnr_tune_hyperparam_lr.png" />
        </div>
      </div>
    </div>

    <p>
      Observing these two graphs, $L = 10$ and $\text{learning_rate} = 0.025$ achieve the highest
      PSNRs. Now, we can use these values to train the model and generate reconstructed images
      throughout training.
    </p>

    <div class="image-container-2">
      <div class="image-item">
        <h4 class="image-title">Original Fox</h4>
        <div class="image-wrapper">
          <img src="media/fox.jpg" alt="fox.jpg" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/fox_psnr.png" alt="fox_psnr.png" />
        </div>
      </div>
    </div>
    <div class="image-container-5">
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/fox_iter_100.png" alt="fox_iter_100.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/fox_iter_200.png" alt="fox_iter_200.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/fox_iter_500.png" alt="fox_iter_500.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/fox_iter_1000.png" alt="fox_iter_1000.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/fox_iter_3000.png" alt="fox_iter_3000.png" />
        </div>
      </div>
    </div>

    <div class="image-container-2">
      <div class="image-item">
        <h4 class="image-title">Original Dog</h4>
        <div class="image-wrapper">
          <img src="media/dog_high_res.jpg" alt="dog_high_res.jpg" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/dog_psnr.png" alt="dog_psnr.png" />
        </div>
      </div>
    </div>
    <div class="image-container-5">
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/dog_iter_100.png" alt="dog_iter_100.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/dog_iter_200.png" alt="dog_iter_200.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/dog_iter_500.png" alt="dog_iter_500.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/dog_iter_1000.png" alt="dog_iter_1000.png" />
        </div>
      </div>
      <div class="image-item">
        <div class="image-wrapper">
          <img src="media/dog_iter_3000.png" alt="dog_iter_3000.png" />
        </div>
      </div>
    </div>

    <p>
      The training took much longer for my dog image than the fox one because the dog is 3072 x 3072
      while the fox is only 689 x 1024. We can see the our neural network learns quite quickly how
      to reconstruct the image as it initially is able to get most of the details, except from some
      blur, but within a few hundred iterations, the reconstructed image very closely resembles the
      original one.
    </p>

    <h2>Part 2: Fit a Neural Radiance Field from Multi-view Images</h2>

    <p>Sinusoidal positional encoding formulas can be computed with the formulas below</p>

    <p>For our neural networks, to get the output dimensions from the positional encoding</p>

    <h2>Bells and Whistles</h2>

    <p>
      For the Bells and Whistles, I chose to do "Render the Lego video with a different background
      color than black..."
    </p>

    <p>
      To achieve this, we can modify the <code>volrend</code> function to take in a background color
      of a tensor with three values for RGB. We will add this code to the end: compute the remaining
      transmittance and add the color contribution to the original color we previously got from the
      original <code>volrend</code>.
    </p>

    <p>This are two resulting GIFs with a background color of white and purple.</p>

    <div class="image-container-2">
      <div class="image-item">
        <h4 class="image-title">White</h4>
        <div class="image-wrapper">
          <img src="media/final_out_white.gif" alt="final_out_white.gif" />
        </div>
      </div>
      <div class="image-item">
        <h4 class="image-title">Purple</h4>
        <div class="image-wrapper">
          <img src="media/final_out_purple.gif" alt="final_out_purple.gif" />
        </div>
      </div>
    </div>

  </body>
</html>
